[ad2258@farnam2 SIPWEB_MiSeq_Prelim001]$ ls -l *.sh
-rw-r--r-- 1 ad2258 dunn   185 Jan  9 14:13 dada2.sh
-rw-r--r-- 1 ad2258 dunn   377 Mar 17 21:15 dsqSAP.sh
-rw-r--r-- 1 ad2258 dunn   186 Jan  9 14:13 FASTQC.sh
-rw-r--r-- 1 ad2258 dunn  8094 Mar 17 21:33 FULLPIPE.sh
-rw-r--r-- 1 ad2258 dunn  1028 Jan  9 14:13 grep_loop.sh
-rwxr-xr-x 1 ad2258 dunn   254 Mar 17 21:33 makelines.sh
-rw-r--r-- 1 ad2258 dunn   415 Mar 17 21:33 OTUwrangletest.sh
-rw-r--r-- 1 ad2258 dunn  1898 Mar 17 21:33 pipe_part3.sh
-rw-r--r-- 1 ad2258 dunn  1615 Mar 17 21:33 pipe_part4.sh
-rw-r--r-- 1 ad2258 dunn   363 Jan  9 14:13 qiime2.sh
-rw-r--r-- 1 ad2258 dunn   299 Mar 17 21:33 run_SAP.sh
-rw-r--r-- 1 ad2258 dunn     0 Mar 17 21:33 runSAP_test134.sh
-rw-r--r-- 1 ad2258 dunn     0 Mar 17 21:33 runSAP_test152.sh
-rw-r--r-- 1 ad2258 dunn     0 Mar 17 21:33 runSAP_test166.sh
-rw-r--r-- 1 ad2258 dunn     0 Mar 17 21:33 runSAP_test179.sh
-rw-r--r-- 1 ad2258 dunn     0 Mar 17 21:33 runSAP_test261.sh
-rw-r--r-- 1 ad2258 dunn     0 Mar 17 21:33 runSAP_test272.sh
-rw-r--r-- 1 ad2258 dunn  1228 Mar 17 22:10 sapwrangle.sh
-rw-r--r-- 1 ad2258 dunn 10560 Mar 17 22:10 single_end_pipe.sh
-rwxr-xr-x 1 ad2258 dunn  2360 Mar 17 22:29 singleSAP_onconsole.sh
-rw-r--r-- 1 ad2258 dunn  2617 Mar 17 22:29 singleSAP.sh
-rw-r--r-- 1 ad2258 dunn  3570 Mar 17 22:29 singleTEST.sh
[ad2258@farnam2 SIPWEB_MiSeq_Prelim001]$ cat *.sh
#!/bin/bash
#SBATCH --job-name=dada2

#SBATCH --partition=general
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=5G
#SBATCH --time=0-13:00:00

Rscript rscriptdada.R
#!/bin/bash
#SBATCH --job-name=deadSAP
#SBATCH --partition=general
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --array=0-999
#SBATCH --mem-per-cpu=5G
#SBATCH --mail-type=END
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=alejandro.damianserrano@yale.edu
#SBATCH --time=0-01:00:00

module load dSQ
dSQ --jobfile SAP_jobfile.txt --mem-per-cpu=4g -t 12:12:00 > runSAP.sh
#!/bin/bash
#SBATCH --job-name=miseq_fastqc

#SBATCH --partition=general
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1

#SBATCH --mem-per-cpu=1G
#SBATCH --time=0-06:00:00

fastqc *.fastq
#!/bin/bash
#SBATCH --job-name=part2pipe
#SBATCH --partition=general
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=5G
#SBATCH --mail-type=END
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=alejandro.damianserrano@yale.edu
#SBATCH --time=1-00:00:00

### USAGE ###

# Make sure the manifest files and metadata files are formatted adequately
# mkdir pipeline_directory
# Have a copy of the manifest and metadata files in the pipeline_directory
# Manifests paths should be $PWD/$bb_output/filename for each filename
# OTUwrangle.R script should be in the pipeline_directory

#############

#Declare temporary variables
runid="test_3seqs"
pipeline_dir="fullpipelinetrial"
barcodes=("152" "166" "272" "179" "261" "134")

rm -rf $pipelinedir/Q2_*

# *** IMPORTANT *** MANIFEST MUST CONTAIN THE PATHS TO BB_OUTPUT!
source activate qiime2-2018.11
module load R-bundle-Bioconductor/3.5-foss-2016b-R-3.4.1

for barcode in ${barcodes[@]}; do

  echo Starting QIIME2 for barcode_"$barcode"

  manifest="$pipeline_dir"/manifest_"$barcode"
  metadata="$pipeline_dir"/metadata_"$barcode".tsv
  exportpath="$pipeline_dir"/Q2_"$barcode"/export

  mkdir "$pipeline_dir"/Q2_"$barcode"
  mkdir $exportpath

  #Load data into QIIME2
  qiime metadata tabulate --m-input-file $metadata --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"_metadata.qzv

  qiime tools import \
     --type 'SampleData[PairedEndSequencesWithQuality]' \
     --input-path $manifest \
     --output-path "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode".qza \
     --input-format PairedEndFastqManifestPhred33

  qiime demux summarize \
    --i-data "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode".qza \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode".qzv

  echo "Paired reads imported into QIIME2!"

  #DADA2 Denoise and dereplicate
  qiime dada2 denoise-paired \
          --i-demultiplexed-seqs "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode".qza \
          --p-trunc-len-f 125 \
          --p-trunc-len-r 125 \
          --o-representative-sequences "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qza \
          --o-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qza \
          --p-n-threads 24 \
          --output-dir "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"_dada2_out

  qiime feature-table summarize \
    --i-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qza \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qzv \
    --m-sample-metadata-file $metadata

  qiime feature-table tabulate-seqs \
    --i-data "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qza \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qzv

  qiime tools export \
    --input-path "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qza \
    --output-path $exportpath

  qiime tools export \
  --input-path "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qza \
  --output-path $exportpath

  echo "Data denoised, merged, and demultiplexed with DADA2!"

  #Multiple seqeunce alignment using Mafft
   qiime alignment mafft \
    --i-sequences "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qza \
    --o-alignment "$pipeline_dir"/Q2_"$barcode"/aligned-rep-"$runid""$barcode".qza

  #Mask the alignment to remove positions that are highly variable.
  qiime alignment mask \
    --i-alignment "$pipeline_dir"/Q2_"$barcode"/aligned-rep-"$runid""$barcode".qza \
    --o-masked-alignment "$pipeline_dir"/Q2_"$barcode"/masked-aligned-rep-"$runid""$barcode".qza

  echo "Sequences aligned!"

  #Create the tree using the Fasttree program
  qiime phylogeny fasttree \
    --i-alignment "$pipeline_dir"/Q2_"$barcode"/masked-aligned-rep-"$runid""$barcode".qza \
    --o-tree "$pipeline_dir"/Q2_"$barcode"/unrooted-"$runid""$barcode".qza

  #Root the tree using the longest root
  qiime phylogeny midpoint-root \
    --i-tree "$pipeline_dir"/Q2_"$barcode"/unrooted-"$runid""$barcode".qza \
    --o-rooted-tree "$pipeline_dir"/Q2_"$barcode"/rooted-"$runid""$barcode".qza

  echo "Phylogenetic tree generated!"

  #Alpha rarefaction
  qiime diversity alpha-rarefaction \
    --i-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qza \
    --i-phylogeny "$pipeline_dir"/Q2_"$barcode"/rooted-"$runid""$barcode".qza \
    --p-max-depth 4000 \
    --m-metadata-file $metadata \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-rarefaction.qzv

  #Alpha diversity metrics
  qiime diversity core-metrics-phylogenetic \
    --i-phylogeny "$pipeline_dir"/Q2_"$barcode"/rooted-"$runid""$barcode".qza \
    --i-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qza \
    --p-sampling-depth 1100 \
    --m-metadata-file $metadata \
    --output-dir "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results

  qiime diversity alpha-group-significance \
    --i-alpha-diversity "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/faith_pd_vector.qza \
    --m-metadata-file $metadata \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/"$runid""$barcode"faith-pd-group-significance.qzv

  qiime diversity alpha-group-significance \
    --i-alpha-diversity "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/evenness_vector.qza \
    --m-metadata-file $metadata \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/"$runid""$barcode"evenness-group-significance.qzv

  qiime diversity alpha-group-significance \
    --i-alpha-diversity "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/shannon_vector.qza \
    --m-metadata-file $metadata \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/"$runid""$barcode"shannon_group-significance.qzv

  #Beta diversity by template
  qiime diversity beta-group-significance \
    --i-distance-matrix "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/unweighted_unifrac_distance_matrix.qza \
    --m-metadata-file $metadata \
    --m-metadata-column template \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/"$runid""$barcode"unweighted-unifrac-template-significance.qzv \
    --p-pairwise

  echo Diversity metrics computed and plotted. End of the QIIME process for barcode "$barcode"

  #Convert feature table to TSV
  biom convert --to-tsv -i "$exportpath"/feature-table.biom -o "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-feature-table.tsv

  #Rename and relocate sequences for all samples
  #cat "$exportpath"/dna-sequences.fasta > "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-sequences.fasta
  head -6 "$exportpath"/dna-sequences.fasta > "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-sequences.fasta

done

echo "QIIME2 loop completed!"

#### ASSIGN TAXONOMY TO AMPLICONS ####

source deactivate qiime2-2018.11
module purge
module load BLAST+/2.7.1-foss-2016b-Python-2.7.13
module load ClustalW2/2.1-foss-2016b
module load R-bundle-Bioconductor/3.5-foss-2016b-R-3.4.1

"Starting SAP loop!"

for barcode in ${barcodes[@]}; do
  echo SAP started for barcode $barcode !
  ~/anaconda2/bin/sap --project "$pipeline_dir"/Q2_"$barcode"/SAP_"$runid"_"$barcode" \
    --email alejandro.damianserrano@yale.edu \
    --minsignificance 0.3 \
    -s 0.1 \
    --minidentity 0.5 \
    -n 10 \
    --ppcutoff 85 \
    --svg "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-sequences.fasta

  pathtoAssignments="$runid"_"$barcode"/assignments.csv
  pathtoFeatures="$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-feature-table.tsv

  #Create table with OTU IDs and frequency in each sample
  Rscript --vanilla "$pipeline_dir"/OTUwrangle.R $runid $barcode $pathtoAssignments $pathtoFeatures "$pipeline_dir"/Q2_"$barcode"
  tail -n +2 "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode""IDtable.tsv" > "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode""_IDtable.tsv"
  rm "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode""IDtable.tsv"

  echo $barcode Sequences identified by SAP!

done

echo "End of the pipeline!"

#!/bin/bash
#SBATCH --job-name=grep_loop_amplicons
#SBATCH --partition=general
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=4G
#SBATCH --time=0-13:00:00

barcodes=("152" "166" "272" "179" "261" "134")
queries=("^TGACGGAAGGGCACCACCAG|^TCCACCAACTAAGAACGGCC|^CTGGTGGTGCCCTTCCGTCA|^GGCCGTTCTTAGTTGGTGGA" "^AACGGCTACCACATCCAAGG|^CACCAGACTTGCCCTCCAAT|^CCTTGGATGTGGTAGCCGTT|^ATTGGAGGGCAAGTCTGGTG" "^AAACGATGCCGACTAGCGAT|^TCCACCAACTAAGAACGGCC|^ATCGCTAGTCGGCATCGTTT|^GGCCGTTCTTAGTTGGTGGA" "^GGCCGTTCTTAGTTGGTGGA|^TGCGGCCCAGAACATCTAAG|^TCCACCAACTAAGAACGGCC|^CTTAGATGTTCTGGGCCGCA" "^AACAGGTCTGTGATGCCCTT|^TGTGTACAAAGGGCAGGGAC|^AAGGGCATCACAGACCTGTT|^GTCCCTGCCCTTTGTACACA" "^CTTTGTACACACCGCCCGTC|^CCTTGTTACGACTTTTACTTCCTCT|^GACGGGCGGTGTGTACAAAG|^AGAGGAAGTAAAAGTCGTAACAAGG")
filenames=($(ls pairedendsequences))

for file in ${filenames[@]}; do
	for bc in 0 1 2 3 4 5; do
		grep -E "${queries[$bc]}" -C 1 -A 2 pairedendsequences/"$file" | sed 's\--\\g' | sed  '/^$/d' >> grep_output/"${barcodes[$bc]}"_"$file"
	done
done#!/bin/bash

splitfiles=($(ls "splitout"))
for i in ${splitfiles[@]}; do

echo ~/anaconda2/bin/sap --project splitSAPs/$i --email alejandro.damianserrano@yale.edu --minsignificance 0.3 -s 0.1 --minidentity 0.5 -n 10 --ppcutoff 85 --svg splitout/$i

done
#!/bin/bash
#SBATCH --job-name=Q2_pipe
#SBATCH --partition=general
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=5G
#SBATCH --time=0-01:00:00

module load R-bundle-Bioconductor/3.5-foss-2016b-R-3.4.1

runid="test_3seqs"
barcode="ALL"
pipeline_dir="fullpipelinetrial"

Rscript --vanilla "$pipeline_dir"/OTUwrangle.R $runid $barcode noprimers_allseqs/assignments.csv featuretable3lines.tsv "."
#!/bin/bash
#SBATCH --job-name=pipe_part3
#SBATCH --partition=general
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=5G
#SBATCH --mail-type=END
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=alejandro.damianserrano@yale.edu
#SBATCH --time=1-00:00:00

runid="test"
pipeline_dir="fullpipelinetrial"
barcodes=("152" "166" "272" "179" "261" "134")
source activate qiime2-2018.11
module load dSQ

for barcode in ${barcodes[@]}; do
  exportpath="$pipeline_dir"/Q2_"$barcode"/export
  biom convert --to-tsv -i "$exportpath"/feature-table.biom -o "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-feature-table.tsv

  #Split sequences in sets of 100 for SAP
  mkdir "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"
  split -l 100 "$exportpath"/dna-sequences.fasta "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"
  #head -6 "$exportpath"/dna-sequences.fasta > "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-3sequences.fasta
  splitfiles=($(ls "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"))
  mkdir "$pipeline_dir"/Q2_"$barcode"/splitSAP"$runid""$barcode"

  #Make DeadSimple jobfile for each fasta subfile
  for i in ${splitfiles[@]}; do
    echo "module load BLAST+/2.7.1-foss-2016b-Python-2.7.13; module load ClustalW2/2.1-foss-2016b; ~/anaconda2/bin/sap --project $pipeline_dir/Q2_$barcode/splitSAP$runid$barcode/$i --email alejandro.damianserrano@yale.edu --minsignificance 0.3 -s 0.1 --minidentity 0.5 -n 10 --ppcutoff 85 --svg $pipeline_dir/Q2_$barcode/splitout$runid$barcode/$i" | cat >> "$pipeline_dir"/Q2_"$barcode"/SAP"$runid""$barcode"_jobfile.txt
  done

  dSQ --jobfile "$pipeline_dir"/Q2_"$barcode"/SAP"$runid""$barcode"_jobfile.txt --mem-per-cpu=4g -t 7-10:00:00 > "$pipeline_dir"/Q2_"$barcode"/runSAP_"$runid""$barcode".sh
  sbatch "$pipeline_dir"/Q2_"$barcode"/runSAP_"$runid""$barcode".sh
  echo SAP started for barcode "$barcode"!

done


#!/bin/bash
#SBATCH --job-name=pipe_part4
#SBATCH --partition=general
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=5G
#SBATCH --mail-type=END
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=alejandro.damianserrano@yale.edu
#SBATCH --time=1-00:00:00

runid="test"
pipeline_dir="fullpipelinetrial"
barcodes=("152" "166" "272" "179" "261" "134")
module load dSQ

for barcode in ${barcodes[@]}; do
  exportpath="$pipeline_dir"/Q2_"$barcode"/export

  #Split sequences in sets of 100 for SAP
  split -l 100 "$exportpath"/dna-sequences.fasta "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"/splitout
  #head -6 "$exportpath"/dna-sequences.fasta > "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-3sequences.fasta
  splitfiles=($(ls "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"))

  #Make DeadSimple jobfile for each fasta subfile
  for i in ${splitfiles[@]}; do
    echo "module load BLAST+/2.7.1-foss-2016b-Python-2.7.13; module load ClustalW2/2.1-foss-2016b; ~/anaconda2/bin/sap --project $pipeline_dir/Q2_$barcode/splitSAP$runid$barcode/$i --email alejandro.damianserrano@yale.edu --minsignificance 0.3 -s 0.1 --minidentity 0.5 -n 10 --ppcutoff 85 --svg $pipeline_dir/Q2_$barcode/splitout$runid$barcode/$i" | cat >> "$pipeline_dir"/Q2_"$barcode"/SAP"$runid""$barcode"_jobfile.txt
  done

  dSQ --jobfile "$pipeline_dir"/Q2_"$barcode"/SAP"$runid""$barcode"_jobfile.txt --mem-per-cpu=4g -t 7-10:00:00 > "$pipeline_dir"/Q2_"$barcode"/runSAP_"$runid""$barcode".sh
  sbatch "$pipeline_dir"/Q2_"$barcode"/runSAP_"$runid""$barcode".sh
  echo SAP started for barcode "$barcode"!

done


#!/bin/bash
#SBATCH --job-name=load_qiime2_qza
#SBATCH --partition=general
#SBATCH --ntasks=5
#SBATCH --cpus-per-task=5
#SBATCH --mem-per-cpu=5G
#SBATCH --time=1-23:00:00

qiime tools import \
   --type 'SampleData[PairedEndSequencesWithQuality]' \
   --input-path manifest \
   --output-path paired-end-demux.qza \
   --input-format PairedEndFastqManifestPhred33#!/bin/bash

#SBATCH --mem-per-cpu=4g
#SBATCH -t 10:10:00
#SBATCH --array=0-100
#SBATCH --job-name=SAP_jobfile.txt
#SBATCH --cpus-per-task=1
#SBATCH --mail-type=ALL
#SBATCH --mail-user=alejandro.damianserrano@yale.edu
#SBATCH --ntasks=1

/ysm-gpfs/apps/software/dSQ/0.92/dSQBatch.py SAP_jobfile.txt
#!/bin/bash
#SBATCH --job-name=SAP-to-Taxa
#SBATCH --partition=general
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=5G
#SBATCH --mail-type=END
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=alejandro.damianserrano@yale.edu
#SBATCH --time=0-05:00:00

module load R-bundle-Bioconductor/3.5-foss-2016b-R-3.4.1
runid="test_3seqs"
pipeline_dir="fullpipelinetrial"
barcodes=("152" "166" "272" "179" "261" "134")

echo "Starting SAP loop!"

for barcode in ${barcodes[@]}; do

  cat "$pipeline_dir"/Q2_"$barcode"/splitSAP"$runid""$barcode"/*/assignments.csv > "$pipeline_dir"/Q2_"$barcode"/"$runid"_"$barcode"_pooled_assignments.csv

  pathtoAssignments="$pipeline_dir"/Q2_"$barcode"/"$runid"_"$barcode"_pooled_assignments.csv
  pathtoFeatures="$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-feature-table.tsv

  #Create table with OTU IDs and frequency in each sample
  Rscript --vanilla "$pipeline_dir"/OTUwrangle.R $runid $barcode $pathtoAssignments $pathtoFeatures "$pipeline_dir"/Q2_"$barcode"
  tail -n +2 "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode""IDtable.tsv" > "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode""_IDtable.tsv"
  rm "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode""IDtable.tsv"

done
#!/bin/bash
#SBATCH --job-name=Single_pipe
#SBATCH --partition=general
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=5G
#SBATCH --mail-type=END
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=alejandro.damianserrano@yale.edu
#SBATCH --time=7-00:00:00

### USAGE ###

# Make sure the manifest files and metadata files are formatted adequately
# mkdir pipeline_directory
# Have a copy of the manifest and metadata files in the pipeline_directory
# Manifests paths should be $PWD/$bb_output/filename for each filename
# OTUwrangle.R script should be in the pipeline_directory

#############

#Load packages
module load FastQC/0.11.5-Java-1.8.0_121
module load BBMap/36.62-foss-2016b-Java-1.8.0_121

echo "Modules and environment loaded!"

#Declare temporary variables
runid="singlend"
pipeline_dir="singlendtrial"
pathtoTARGZs="/SAY/archive/cwd7-11174224-FASEEB-A/data/sequences/illumina/SIPHWEB_MiSeq_Preliminary_001"
pathtoFASTQs=$pipeline_dir"/fastq_files"
pathtoHTMLS=$pipeline_dir"/fastqc_HTMLs"
barcodes=("152" "166" "272" "179" "261" "134")
queries=("^TGACGGAAGGGCACCACCAG|^TCCACCAACTAAGAACGGCC|^CTGGTGGTGCCCTTCCGTCA|^GGCCGTTCTTAGTTGGTGGA" "^AACGGCTACCACATCCAAGG|^CACCAGACTTGCCCTCCAAT|^CCTTGGATGTGGTAGCCGTT|^ATTGGAGGGCAAGTCTGGTG" "^AAACGATGCCGACTAGCGAT|^TCCACCAACTAAGAACGGCC|^ATCGCTAGTCGGCATCGTTT|^GGCCGTTCTTAGTTGGTGGA" "^GGCCGTTCTTAGTTGGTGGA|^TGCGGCCCAGAACATCTAAG|^TCCACCAACTAAGAACGGCC|^CTTAGATGTTCTGGGCCGCA" "^AACAGGTCTGTGATGCCCTT|^TGTGTACAAAGGGCAGGGAC|^AAGGGCATCACAGACCTGTT|^GTCCCTGCCCTTTGTACACA" "^CTTTGTACACACCGCCCGTC|^CCTTGTTACGACTTTTACTTCCTCT|^GACGGGCGGTGTGTACAAAG|^AGAGGAAGTAAAAGTCGTAACAAGG")
grep_output=$pipeline_dir/"grep_output"
bb_output=$pipeline_dir"/bb_output"
bb_orphans=$pipeline_dir"bb_orphans"
cutadapt_o=$pipeline_dir"/cutadapt_o"

mkdir $pathtoFASTQs
mkdir $pathtoHTMLS
mkdir $grep_output
mkdir $bb_output
mkdir $bb_orphans
mkdir $cutadapt_o

echo "Directories and paths declared!"

#Extract GZ balls
gzfiles=($(ls "$pathtoTARGZs"))
for f in ${gzfiles[@]}; do gunzip -c "$pathtoTARGZs"/"$f" > "$pathtoFASTQs"/"${f%.*}" ; done

echo ".gz files extracted!"

#Quality HTMLS
fastqc "$pathtoFASTQs"/* -o $pathtoHTMLS

echo "Fastqc quality html reports generated!"

#Segragate by Barcode/Amplicon
filenames=($(ls "$pathtoFASTQs")) #for the grep by amplicon stage
for file in ${filenames[@]}; do
	for bc in 0 1 2 3 4 5; do
		grep -E "${queries[$bc]}" -C 1 -A 2 pairedendsequences/"$file"  | sed 's\^--$\\g' | sed '/^$/d' >> "$grep_output"/"${barcodes[$bc]}"_"$file"
	done
done

echo "Reads sorted by PCR primers into the 6 different amplicons!"

#Remove PCR primers
files=($(ls "$grep_output")) #for the cutadapt PCR primer removal
for file in ${files[@]}; do
	cutadapt -m 50 -g ^TGACGGAAGGGCACCACCAG -g ^TCCACCAACTAAGAACGGCC -g ^CTGGTGGTGCCCTTCCGTCA -g ^GGCCGTTCTTAGTTGGTGGA  -g ^AACGGCTACCACATCCAAGG -g ^CACCAGACTTGCCCTCCAAT -g ^CCTTGGATGTGGTAGCCGTT -g ^ATTGGAGGGCAAGTCTGGTG  -g ^AAACGATGCCGACTAGCGAT -g ^TCCACCAACTAAGAACGGCC -g ^ATCGCTAGTCGGCATCGTTT -g ^GGCCGTTCTTAGTTGGTGGA  -g ^GGCCGTTCTTAGTTGGTGGA -g ^TGCGGCCCAGAACATCTAAG -g ^TCCACCAACTAAGAACGGCC -g ^CTTAGATGTTCTGGGCCGCA  -g ^AACAGGTCTGTGATGCCCTT -g ^TGTGTACAAAGGGCAGGGAC -g ^AAGGGCATCACAGACCTGTT -g ^GTCCCTGCCCTTTGTACACA  -g ^CTTTGTACACACCGCCCGTC -g ^CCTTGTTACGACTTTTACTTCCTCT -g ^GACGGGCGGTGTGTACAAAG -g ^AGAGGAAGTAAAAGTCGTAACAAGG -o "$cutadapt_o"/"$file" "$grep_output"/"$file"
done

echo "PCR primer sequences removed from the 5' end!"

# *** IMPORTANT *** MANIFEST MUST CONTAIN THE PATHS TO BB_OUTPUT!
module purge
source activate qiime2-2018.11
module load R-bundle-Bioconductor/3.5-foss-2016b-R-3.4.1
module load dSQ

for barcode in ${barcodes[@]}; do

  echo Starting QIIME2 for barcode_"$barcode"

  manifest="$pipeline_dir"/manifest_"$barcode"
  metadata="$pipeline_dir"/metadata_"$barcode".tsv
  exportpath="$pipeline_dir"/Q2_"$barcode"/export

  mkdir "$pipeline_dir"/Q2_"$barcode"
  mkdir $exportpath

  #Load data into QIIME2
  qiime metadata tabulate --m-input-file $metadata --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"_metadata.qzv

  qiime tools import \
     --type 'SampleData[SingleEndSequencesWithQuality]' \
     --input-path $manifest \
     --output-path "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode".qza \
     --input-format SingleEndFastqManifestPhred33

  qiime demux summarize \
    --i-data "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode".qza \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode".qzv

  echo "Paired reads imported into QIIME2!"

  #DADA2 Denoise and dereplicate
  qiime dada2 denoise-paired \
          --i-demultiplexed-seqs "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode".qza \
          --p-trunc-len-f 90 \
          --p-trunc-len-r 90 \
          --o-representative-sequences "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qza \
          --o-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qza \
          --p-n-threads 24 \
          --output-dir "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"_dada2_out

  qiime feature-table summarize \
    --i-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qza \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qzv \
    --m-sample-metadata-file $metadata

  qiime feature-table tabulate-seqs \
    --i-data "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qza \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qzv

  qiime vsearch cluster-features-de-novo \
  --i-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qza \
  --i-sequences "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qza \
  --p-perc-identity 0.95 \
  --o-clustered-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-095-table.qza \
  --o-clustered-sequences "$pipeline_dir"/Q2_"$barcode"/rep-095-"$runid""$barcode".qza

  qiime tools export \
    --input-path "$pipeline_dir"/Q2_"$barcode"/rep-095-"$runid""$barcode".qza \
    --output-path $exportpath

  qiime tools export \
  --input-path "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-095-table.qza \
  --output-path $exportpath

  echo "Data denoised, merged, and demultiplexed with DADA2 and clustered with VSEARCH!"

  #Multiple seqeunce alignment using Mafft
   qiime alignment mafft \
    --i-sequences "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qza \
    --o-alignment "$pipeline_dir"/Q2_"$barcode"/aligned-rep-"$runid""$barcode".qza

  #Mask the alignment to remove positions that are highly variable.
  qiime alignment mask \
    --i-alignment "$pipeline_dir"/Q2_"$barcode"/aligned-rep-"$runid""$barcode".qza \
    --o-masked-alignment "$pipeline_dir"/Q2_"$barcode"/masked-aligned-rep-"$runid""$barcode".qza

  echo "Sequences aligned!"

  #Create the tree using the Fasttree program
  qiime phylogeny fasttree \
    --i-alignment "$pipeline_dir"/Q2_"$barcode"/masked-aligned-rep-"$runid""$barcode".qza \
    --o-tree "$pipeline_dir"/Q2_"$barcode"/unrooted-"$runid""$barcode".qza

  #Root the tree using the longest root
  qiime phylogeny midpoint-root \
    --i-tree "$pipeline_dir"/Q2_"$barcode"/unrooted-"$runid""$barcode".qza \
    --o-rooted-tree "$pipeline_dir"/Q2_"$barcode"/rooted-"$runid""$barcode".qza

  echo "Phylogenetic tree generated!"

  #Alpha rarefaction
  qiime diversity alpha-rarefaction \
    --i-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qza \
    --i-phylogeny "$pipeline_dir"/Q2_"$barcode"/rooted-"$runid""$barcode".qza \
    --p-max-depth 4000 \
    --m-metadata-file $metadata \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-rarefaction.qzv

  #Alpha diversity metrics
  qiime diversity core-metrics-phylogenetic \
    --i-phylogeny "$pipeline_dir"/Q2_"$barcode"/rooted-"$runid""$barcode".qza \
    --i-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qza \
    --p-sampling-depth 1100 \
    --m-metadata-file $metadata \
    --output-dir "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results

  qiime diversity alpha-group-significance \
    --i-alpha-diversity "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/faith_pd_vector.qza \
    --m-metadata-file $metadata \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/"$runid""$barcode"faith-pd-group-significance.qzv

  qiime diversity alpha-group-significance \
    --i-alpha-diversity "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/evenness_vector.qza \
    --m-metadata-file $metadata \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/"$runid""$barcode"evenness-group-significance.qzv

  qiime diversity alpha-group-significance \
    --i-alpha-diversity "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/shannon_vector.qza \
    --m-metadata-file $metadata \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-metrics-results/"$runid""$barcode"shannon_group-significance.qzv

  echo Diversity metrics computed and plotted. End of the QIIME process for barcode "$barcode"

  #Convert feature table to TSV
  biom convert --to-tsv -i "$exportpath"/feature-table.biom -o "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-feature-table.tsv

  #Split sequences in sets of 100 for SAP
  mkdir "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"
  split -l 100 "$exportpath"/dna-sequences.fasta "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"/splitout
  #head -6 "$exportpath"/dna-sequences.fasta > "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-3sequences.fasta
  splitfiles=($(ls "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"))
  mkdir "$pipeline_dir"/Q2_"$barcode"/splitSAP"$runid""$barcode"

  #Make DeadSimple jobfile for each fasta subfile
  for i in ${splitfiles[@]}; do
    echo "module load BLAST+/2.7.1-foss-2016b-Python-2.7.13; module load ClustalW2/2.1-foss-2016b; ~/anaconda2/bin/sap --project $pipeline_dir/Q2_$barcode/splitSAP$runid$barcode/$i --email alejandro.damianserrano@yale.edu --minsignificance 0.3 -s 0.1 --minidentity 0.5 -n 10 --ppcutoff 85 --svg $pipeline_dir/Q2_$barcode/splitout$runid$barcode/$i" | cat >> "$pipeline_dir"/Q2_"$barcode"/SAP"$runid""$barcode"_jobfile.txt
  done

  dSQ --jobfile "$pipeline_dir"/Q2_"$barcode"/SAP"$runid""$barcode"_jobfile.txt --mem-per-cpu=4g -t 7-10:00:00 > "$pipeline_dir"/Q2_"$barcode"/runSAP_"$runid""$barcode".sh
  sbatch "$pipeline_dir"/Q2_"$barcode"/runSAP_"$runid""$barcode".sh
  echo SAP started for barcode "$barcode"!
done
echo "QIIME2 loop completed!"

echo "End of the pipeline!"
#!/bin/bash

#Declare temporary variables
runid="singlend"
pipeline_dir="singlendtrial"
pathtoFASTQs=fullpipelinetrial"/fastq_files"
barcodes=("152" "166" "272" "179" "261" "134")
queries=("^TGACGGAAGGGCACCACCAG|^TCCACCAACTAAGAACGGCC|^CTGGTGGTGCCCTTCCGTCA|^GGCCGTTCTTAGTTGGTGGA" "^AACGGCTACCACATCCAAGG|^CACCAGACTTGCCCTCCAAT|^CCTTGGATGTGGTAGCCGTT|^ATTGGAGGGCAAGTCTGGTG" "^AAACGATGCCGACTAGCGAT|^TCCACCAACTAAGAACGGCC|^ATCGCTAGTCGGCATCGTTT|^GGCCGTTCTTAGTTGGTGGA" "^GGCCGTTCTTAGTTGGTGGA|^TGCGGCCCAGAACATCTAAG|^TCCACCAACTAAGAACGGCC|^CTTAGATGTTCTGGGCCGCA" "^AACAGGTCTGTGATGCCCTT|^TGTGTACAAAGGGCAGGGAC|^AAGGGCATCACAGACCTGTT|^GTCCCTGCCCTTTGTACACA" "^CTTTGTACACACCGCCCGTC|^CCTTGTTACGACTTTTACTTCCTCT|^GACGGGCGGTGTGTACAAAG|^AGAGGAAGTAAAAGTCGTAACAAGG")
grep_output=$pipeline_dir/"grep_output"
cutadapt_o=$pipeline_dir"/cutadapt_o"

source activate qiime2-2018.11
module load dSQ
for barcode in ${barcodes[@]}; do
  exportpath="$pipeline_dir"/Q2_"$barcode"/export
  biom convert --to-tsv -i "$exportpath"/feature-table.biom -o "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-feature-table.tsv

  #Split sequences in sets of 100 for SAP
  mkdir "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"
  split -l 100 "$exportpath"/dna-sequences.fasta "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"/splitout
  #head -6 "$exportpath"/dna-sequences.fasta > "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-3sequences.fasta
  splitfiles=($(ls "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"))
  mkdir "$pipeline_dir"/Q2_"$barcode"/splitSAP"$runid""$barcode"

  #Make DeadSimple jobfile for each fasta subfile
  for i in ${splitfiles[@]}; do
    echo "module load BLAST+/2.7.1-foss-2016b-Python-2.7.13; module load ClustalW2/2.1-foss-2016b; ~/anaconda2/bin/sap --project $pipeline_dir/Q2_$barcode/splitSAP$runid$barcode/$i --email alejandro.damianserrano@yale.edu --minsignificance 0.3 -s 0.1 --minidentity 0.5 -n 10 --ppcutoff 85 --svg $pipeline_dir/Q2_$barcode/splitout$runid$barcode/$i" | cat >> "$pipeline_dir"/Q2_"$barcode"/SAP"$runid""$barcode"_jobfile.txt
  done

  dSQ --jobfile "$pipeline_dir"/Q2_"$barcode"/SAP"$runid""$barcode"_jobfile.txt --mem-per-cpu=4g -t 7-10:00:00 > "$pipeline_dir"/Q2_"$barcode"/runSAP_"$runid""$barcode".sh
  sbatch "$pipeline_dir"/Q2_"$barcode"/runSAP_"$runid""$barcode".sh
  echo SAP started for barcode "$barcode"!

done
#!/bin/bash
#SBATCH --job-name=SingleSAP
#SBATCH --partition=general
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=4G
#SBATCH --mail-type=END
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=alejandro.damianserrano@yale.edu
#SBATCH --time=0-00:40:00

#Declare temporary variables
runid="singlend"
pipeline_dir="singlendtrial"
pathtoFASTQs=fullpipelinetrial"/fastq_files"
barcodes=("152" "166" "272" "179" "261" "134")
queries=("^TGACGGAAGGGCACCACCAG|^TCCACCAACTAAGAACGGCC|^CTGGTGGTGCCCTTCCGTCA|^GGCCGTTCTTAGTTGGTGGA" "^AACGGCTACCACATCCAAGG|^CACCAGACTTGCCCTCCAAT|^CCTTGGATGTGGTAGCCGTT|^ATTGGAGGGCAAGTCTGGTG" "^AAACGATGCCGACTAGCGAT|^TCCACCAACTAAGAACGGCC|^ATCGCTAGTCGGCATCGTTT|^GGCCGTTCTTAGTTGGTGGA" "^GGCCGTTCTTAGTTGGTGGA|^TGCGGCCCAGAACATCTAAG|^TCCACCAACTAAGAACGGCC|^CTTAGATGTTCTGGGCCGCA" "^AACAGGTCTGTGATGCCCTT|^TGTGTACAAAGGGCAGGGAC|^AAGGGCATCACAGACCTGTT|^GTCCCTGCCCTTTGTACACA" "^CTTTGTACACACCGCCCGTC|^CCTTGTTACGACTTTTACTTCCTCT|^GACGGGCGGTGTGTACAAAG|^AGAGGAAGTAAAAGTCGTAACAAGG")
grep_output=$pipeline_dir/"grep_output"
cutadapt_o=$pipeline_dir"/cutadapt_o"

source activate qiime2-2018.11
module load dSQ
for barcode in ${barcodes[@]}; do
  exportpath="$pipeline_dir"/Q2_"$barcode"/export
  biom convert --to-tsv -i "$exportpath"/feature-table.biom -o "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-feature-table.tsv

  #Split sequences in sets of 100 for SAP
  mkdir "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"
  split -l 100 "$exportpath"/dna-sequences.fasta "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"/splitout
  #head -6 "$exportpath"/dna-sequences.fasta > "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-3sequences.fasta
  splitfiles=($(ls "$pipeline_dir"/Q2_"$barcode"/splitout"$runid""$barcode"))
  mkdir "$pipeline_dir"/Q2_"$barcode"/splitSAP"$runid""$barcode"

  #Make DeadSimple jobfile for each fasta subfile
  for i in ${splitfiles[@]}; do
    echo "module load BLAST+/2.7.1-foss-2016b-Python-2.7.13; module load ClustalW2/2.1-foss-2016b; ~/anaconda2/bin/sap --project $pipeline_dir/Q2_$barcode/splitSAP$runid$barcode/$i --email alejandro.damianserrano@yale.edu --minsignificance 0.3 -s 0.1 --minidentity 0.5 -n 10 --ppcutoff 85 --svg $pipeline_dir/Q2_$barcode/splitout$runid$barcode/$i" | cat >> "$pipeline_dir"/Q2_"$barcode"/SAP"$runid""$barcode"_jobfile.txt
  done

  dSQ --jobfile "$pipeline_dir"/Q2_"$barcode"/SAP"$runid""$barcode"_jobfile.txt --mem-per-cpu=4g -t 7-10:00:00 > "$pipeline_dir"/Q2_"$barcode"/runSAP_"$runid""$barcode".sh
  sbatch "$pipeline_dir"/Q2_"$barcode"/runSAP_"$runid""$barcode".sh
  echo SAP started for barcode "$barcode"!

done
#!/bin/bash
#SBATCH --job-name=SingleTEST
#SBATCH --partition=general
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=5G
#SBATCH --mail-type=END
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=alejandro.damianserrano@yale.edu
#SBATCH --time=7-00:00:00

source activate qiime2-2018.11

#Declare temporary variables
runid="singlend"
pipeline_dir="singlendtrial"
pathtoFASTQs=fullpipelinetrial"/fastq_files"
barcodes=("152" "166" "272" "179" "261" "134")
queries=("^TGACGGAAGGGCACCACCAG|^TCCACCAACTAAGAACGGCC|^CTGGTGGTGCCCTTCCGTCA|^GGCCGTTCTTAGTTGGTGGA" "^AACGGCTACCACATCCAAGG|^CACCAGACTTGCCCTCCAAT|^CCTTGGATGTGGTAGCCGTT|^ATTGGAGGGCAAGTCTGGTG" "^AAACGATGCCGACTAGCGAT|^TCCACCAACTAAGAACGGCC|^ATCGCTAGTCGGCATCGTTT|^GGCCGTTCTTAGTTGGTGGA" "^GGCCGTTCTTAGTTGGTGGA|^TGCGGCCCAGAACATCTAAG|^TCCACCAACTAAGAACGGCC|^CTTAGATGTTCTGGGCCGCA" "^AACAGGTCTGTGATGCCCTT|^TGTGTACAAAGGGCAGGGAC|^AAGGGCATCACAGACCTGTT|^GTCCCTGCCCTTTGTACACA" "^CTTTGTACACACCGCCCGTC|^CCTTGTTACGACTTTTACTTCCTCT|^GACGGGCGGTGTGTACAAAG|^AGAGGAAGTAAAAGTCGTAACAAGG")
grep_output=$pipeline_dir/"grep_output"
cutadapt_o=$pipeline_dir"/cutadapt_o"

echo "Directories and paths declared!"

for barcode in ${barcodes[@]}; do

  echo Starting QIIME2 for barcode_"$barcode"

  manifest="$pipeline_dir"/manifest_se_"$barcode"
  metadata="$pipeline_dir"/metadata_"$barcode".tsv
  exportpath="$pipeline_dir"/Q2_"$barcode"/export

  #Load data into QIIME2

  qiime tools import \
     --type 'SampleData[SequencesWithQuality]' \
     --input-path $manifest \
     --output-path "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode".qza \
     --input-format SingleEndFastqManifestPhred33

  qiime demux summarize \
    --i-data "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode".qza \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode".qzv

  echo "Paired reads imported into QIIME2!"

  #DADA2 Denoise and dereplicate
  qiime dada2 denoise-single \
          --i-demultiplexed-seqs "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode".qza \
          --p-trunc-len 90 \
          --o-representative-sequences "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qza \
          --o-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qza \
          --p-n-threads 24 \
          --output-dir "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"_dada2_out

  qiime feature-table summarize \
    --i-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qza \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qzv \
    --m-sample-metadata-file $metadata

  qiime feature-table tabulate-seqs \
    --i-data "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qza \
    --o-visualization "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qzv

  qiime vsearch cluster-features-de-novo \
    --i-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-table.qza \
    --i-sequences "$pipeline_dir"/Q2_"$barcode"/rep-"$runid""$barcode".qza \
    --p-perc-identity 0.95 \
    --o-clustered-table "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-095-table.qza \
    --o-clustered-sequences "$pipeline_dir"/Q2_"$barcode"/rep-095-"$runid""$barcode".qza

  qiime tools export \
    --input-path "$pipeline_dir"/Q2_"$barcode"/rep-095-"$runid""$barcode".qza \
    --output-path $exportpath

  qiime tools export \
  --input-path "$pipeline_dir"/Q2_"$barcode"/"$runid""$barcode"-095-table.qza \
  --output-path $exportpath

  echo "Data denoised, merged, and demultiplexed with DADA2 and clustered with VSEARCH!"

done
echo "QIIME2 loop completed!"

echo "End of the pipeline!"